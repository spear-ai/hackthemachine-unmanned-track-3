{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Notebook for ProcGen Starter Kit with Single Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"config\", \"sagemaker_config.yaml\")) as f:\n",
    "    sagemaker_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://aan-bucket/\n"
     ]
    }
   ],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sagemaker_config[\"S3_BUCKET\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::056313310996:role/service-role/sagemaker-sandbox-exection-role\n"
     ]
    }
   ],
   "source": [
    "job_name_prefix = 'sm-ray-htm'\n",
    "\n",
    "instance_type=\"ml.p3.2xlarge\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = sagemaker_config[\"CPU_TRAINING_INSTANCE\"]\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash source/common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the framework you want to use\n",
    "\n",
    "Set `framework` to `\"tf\"` or `\"torch\"` for tensorflow or pytorch respectively.\n",
    "\n",
    "You will also have to edit your entry point i.e., `train-sagemaker.py` with the configuration parameter `\"use_pytorch\"` to match the framework that you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = \"torch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RL model using the Python SDK Script mode\n",
    "\n",
    "If you are using local mode, the training will run on the notebook instance. \n",
    "\n",
    "When using SageMaker for training, you can select a GPU or CPU instance. The RLEstimator is used for training RL jobs.\n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the custom image to be used for the training environment.\n",
    "4. Define the training parameters such as the instance count, job name, S3 path for output and job name.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Choose](https://github.com/aws/sagemaker-rl-container#rl-images-provided-by-sagemaker) which docker image to use based on the instance type.* \n",
    "For this notebook, it has to be a container with Ray 0.8.5 and TensorFlow 2.1.0 to be consistent with the AICrowd ProcGen starter kit. \n",
    "\n",
    "If you prefer to use PyTorch, it is recommended to update your notebook kernel to `conda_pytorch_p36`. You would need to substitute for the corresponding container listed on Amazon SageMaker Reinforcement Learning documentation. In addition, you will need to ensure your starter kit is modified to train using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'462105765813.dkr.ecr.us-west-2.amazonaws.com/sagemaker-rl-ray-container:ray-1.6.0-torch-gpu-py36'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_or_gpu = 'gpu' if instance_type.startswith(('ml.p', 'ml.g')) else 'cpu'\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "custom_image_name = \"462105765813.dkr.ecr.{}.amazonaws.com/sagemaker-rl-ray-container:ray-1.6.0-{}-{}-py36\".format(aws_region, framework, cpu_or_gpu)\n",
    "custom_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics still work in progress. Currently REGEX is not working with SageMaker env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions =  [\n",
    "    {'Name': 'training_iteration', 'Regex': 'Result for PPO_.*training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episodes_total', 'Regex': 'Result for PPO_.*episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'num_steps_trained', 'Regex': 'Result for PPO_.*num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'Result for PPO_.*timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'training_iteration', 'Regex': 'Result for PPO_.*training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'episode_reward_max', 'Regex': 'Result for PPO_.*episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_mean', 'Regex': 'Result for PPO_.*episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_min', 'Regex': 'Result for PPO_.*episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the RL estimator\n",
    "\n",
    "There are 16 environments to choose from. You can run the RL estimator on multiple environments by proving a list of environments as well. The RL estimator will start the training job. This will take longer compared to the above cells, be patient. You can monitor the status of your training job from the console as well, go to Amazon SageMaker > Training jobs. The most recent job will be at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm-ray-spearai-tiger-2021-12-10-04-13-13-739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator = RLEstimator(entry_point=\"train-sagemaker.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"src/utils\", \"src/common/\"],\n",
    "                        image_uri=custom_image_name,\n",
    "                        role=role,\n",
    "                        max_run=172800,\n",
    "                        instance_type=instance_type,\n",
    "                        instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix + \"-\" + 'tiger',\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        debugger_hook_config=False,\n",
    "                        hyperparameters={\n",
    "                            \"rl.training.run\": \"PPO\",\n",
    "                            \"rl.training.stop.episodes_total\": 10000,\n",
    "                            \"rl.training.config.framework\": \"torch\",\n",
    "#                             \"rl.training.config.log_level\": \"WARN\",\n",
    "                            \"rl.training.config.env\": \"drug_runner\",\n",
    "                            \"rl.training.config.gamma\": 0.99,\n",
    "                            \"rl.training.config.use_gae\": True,\n",
    "                            \"rl.training.config.lambda\": 0.9,\n",
    "                            \"rl.training.config.kl_coeff\": 1.0,\n",
    "                            \"rl.training.config.num_sgd_iter\": 20,\n",
    "                            \"rl.training.config.compress_observations\": True,\n",
    "                            \"rl.training.config.lr\": 2e-05,\n",
    "                            \"rl.training.config.grad_clip\": 0.001,\n",
    "                            \"rl.training.config.clip_param\": 0.4,\n",
    "                            \"rl.training.config.vf_loss_coeff\": 0.25,\n",
    "                            \"rl.training.config.sgd_minibatch_size\": 8,\n",
    "                            \"rl.training.config.train_batch_size\": 64,\n",
    "                            \"rl.training.config.num_workers\": 2,\n",
    "                            \"rl.training.config.num_cpus_per_worker\": 3,\n",
    "                            \"rl.training.config.num_gpus_per_worker\": 0,\n",
    "                            \"rl.training.config.num_envs_per_worker\": 1,\n",
    "                            \"rl.training.config.num_gpus\": 1,\n",
    "                            \"rl.training.config.rollout_fragment_length\": 16,\n",
    "                            \"rl.training.config.batch_mode\": \"truncate_episodes\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "estimator.fit(wait=False)\n",
    "\n",
    "print(estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
